{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import CAM_NWB as cn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = ('/Volumes/Brain2015/CAM/')\n",
    "group = ('185282')\n",
    "baseline_method = ('_mean_preStim_responses.npy')\n",
    "traces = np.load(path + 'traces_' + group + '.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pklfile = open(path+'CAM_Meta.pkl','r') # importing the compiled CAM meta data\n",
    "CAM_Meta = pickle.load(pklfile)\n",
    "pklfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAM_Meta_X = CAM_Meta[(CAM_Meta.specimen==group)]\n",
    "group_ids = list(CAM_Meta_X.lims_id)\n",
    "len(group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 482923718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tuning={}\n",
    "for x, filename in enumerate(group_ids[:1]):\n",
    "    print x,filename\n",
    "    exp_traces = traces[x]\n",
    "    baseline = np.load(path + 'baselines' + '/' + filename + baseline_method)\n",
    "    baseline = baseline.T\n",
    "    DFF_traces = np.nan*np.ones(exp_traces.shape)\n",
    "    for counter in range(DFF_traces.shape[2]): #DF/F calculation (exp_traces/baseline)-1\n",
    "        DFF_traces[:,:,counter] = (exp_traces[:,:,counter]/baseline)-1\n",
    "    \n",
    "    mean_response= np.mean(DFF_traces[:,:,30:90], axis=2)\n",
    "    stimparams = cn.getStimulusTable(path + filename + '/' + filename + '.nwb')\n",
    "    \n",
    "    orientations = np.unique(stimparams['orientation'])\n",
    "    orientations = orientations[~np.isnan(orientations)]\n",
    "\n",
    "    TFs = np.unique(stimparams['temporal_frequency'])\n",
    "    TFs = TFs[~np.isnan(TFs)]\n",
    "    \n",
    "    summary_order = ['Orientation','Temporal_Frequency','# Trials']\n",
    "    stim_response = pd.DataFrame(index = range(len(orientations)*len(TFs)), \n",
    "                             columns = summary_order + range(mean_response.shape[0]))\n",
    " \n",
    "    \n",
    "    blank_index = stimparams[(stimparams.blank_sweep)==1].index\n",
    "    blank_trials = DFF_traces[:,blank_index,:]\n",
    "    blank_mean = np.mean(mean_response[:,blank_index], axis=1)\n",
    "    blank_sd = np.std(mean_response[:,blank_index], axis=1)\n",
    "    \n",
    "    \n",
    "    s=0\n",
    "\n",
    "    for i, ori in enumerate(orientations):\n",
    "        for k, tf in enumerate(TFs):\n",
    "            stimpairs= stimparams[(stimparams.orientation==ori) & (stimparams.temporal_frequency==tf)]\n",
    "            stimpairs_index = list(stimpairs.index)\n",
    "            std_response = np.std(mean_response[:,stimpairs_index], axis=1)\n",
    "            stim_response_dict = {'Orientation': ori, 'Temporal_Frequency': tf,'#Trials': len(stimpairs_index)} \n",
    "            response_dict = {counter: response for counter, response in enumerate(response)}\n",
    "            stim_response_dict.update(response_dict)\n",
    "            stim_response.loc[s] = pd.Series(stim_response_dict)\n",
    "            s=s+1\n",
    "            \n",
    "    temptuning=pd.DataFrame(index=range(DFF_traces.shape[0]), columns = ['ROI'] + summary_order[:2])\n",
    "    for roi in range(DFF_traces.shape[0]):\n",
    "        peak = stim_response[roi].idxmax()\n",
    "        ori_tune = stim_response.Orientation[peak]\n",
    "        ori_orth = ori_tune-90\n",
    "        tf_tune = stim_response.Temporal_Frequency[peak]\n",
    "        #orth_response = stim_response\n",
    "        tuning_dict = {'ROI':roi,'Orientation':ori_tune,'Temporal_Frequency':tf_tune}\n",
    "        temptuning.loc[roi] = pd.Series(tuning_dict)\n",
    "        \n",
    "    tuning[filename] = temptuning\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
